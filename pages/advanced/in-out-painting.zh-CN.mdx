import { Steps, Callout, Tabs } from 'nextra-theme-docs';
import { PhotoProvider, PhotoView } from 'react-image-previewer';
import Subscribe from "components/subscribtion";

# In/Outpainting

当你使用 Stable Diffusion 生成完图片后，你可能对图片里的某些部分不太满意。比如，你对图片里的人物头发不满意，你可能会通过修改 Prompt 的方式，比如添加了 red hair，然后重新生成图片。但使用这种方式人物的头像变成了红色，可能其他地方也会发生变化。

那要如何不影响其他地方的，只改变某一区域呢？

<Callout type="warning" emoji="⚠️">
  正式开始学习本章前，请先下载以下模型，并将模型文件放到对应的文件夹内：
  * [Dreamshaper 8-inpainting](https://civitai.com/models/4384?modelVersionId=131004)：将其放到 ComfyUI 里的 models/checkpoints 文件夹内。
</Callout>

## Inpainting workflow

我以下面这个场景为例解释下如何搭建 Inpainting，左侧这张图是我先用文生图功能生成的，我对图中人物的发色不满意，于是我用 ComfyUI 在原图的基础上重新生成了红色头发的人物，且对比原图，新图片除了头发外，其他地方都没有发生变化：
<PhotoProvider>
  <PhotoView src="/comfyui-inoutpainting/003.png">
      <img src="/comfyui-inoutpainting/003.png" alt="" />
  </PhotoView>
</PhotoProvider>

要想将图片里的某一部分替换成其他，主要用到的技术是 Inpainting，其步骤跟图生图很像：

<Steps>
  ### 添加 VAE Encode(for Inpainting)
  按照惯例，我们先从默认的 workflow 开始。点击右侧面板里的 Load Default 按钮加载默认 workflow。然后双击空白处，输入 Inpainting，添加该节点。你会看到这个节点上有个 grow_mask_by 的配置项，我这一般会设置成 6～8。一般来说，这个值越大越好，新生成的图片部分会跟原图融合得越自然。

  ### 添加 Load Image 节点
  添加完节点后，加载你想要修改的图片。并将 Load Image 节点和 VAE Encode（for Inpainting）相连。VAE Encode（for Inpainting）和 KSampler 相连。

  ### 涂抹出想要修改的区域
  连完所有连线后。右键点击 Load Image 节点，在菜单里点击 Open in MaskEditor。进入到 MaskEditor 后，可以涂抹出你想要修改的地方，比如我想要将图片中的人物的头发改成红色，我只要涂抹图片中人物的头发即可。另外，你可以使用下方的 Thickness 修改笔刷的大小。完成后，点击右下角的 Save to node 即可。
  <br/>
  <PhotoProvider>
    <PhotoView src="/comfyui-inoutpainting/001.png">
        <img src="/comfyui-inoutpainting/001.png" alt="" />
    </PhotoView>
  </PhotoProvider>

  ### 切换模型 & 配置
  接着，将 Load Checkpoint 里的模型切换成 inpainting 模型。这里有一个技巧，使用 Inpainting 的模型最好和初始图片使用的模型一致，比如我要修改的这张宇航员图片是用 Dreamshaper 生成的，所以在 Inpainting 场景我用的是 Dreamshaper 的 Inpainting 模型。
  
  除了要调整模型外，还需要将 KSampler 里的 denosie 调成 0.85，当然你也可以根据自己的测试来，越小就越像原图。
  
  ### 输入 prompt
  最后，就是在 positive prompt 上输入你要修改的 prompt。比如我是要将头发颜色改为红色，我就输入 red hair。然后点击 Queue Prompt 即可生成图片了：
  <br/>
  <PhotoProvider>
    <PhotoView src="/comfyui-inoutpainting/002.png">
        <img src="/comfyui-inoutpainting/002.png" alt="" />
    </PhotoView>
  </PhotoProvider>
</Steps>

## Outpainting workflow

除了修改部分内容外，还有一个常见需求是将原来的图片扩大。比如还是上面那个宇航员的例子，宇航员的右手和下肢都没有生成出来，我希望 AI 能继续生成，比如像这样：
<br/>
<PhotoProvider>
  <PhotoView src="/comfyui-inoutpainting/004.png">
      <img src="/comfyui-inoutpainting/004.png" alt="" />
  </PhotoView>
</PhotoProvider>

步骤跟 Inpainting 差不多，所以你可以继续使用 Inpainting 的 workflow：
<Steps>
  ### 添加 Pad Image for Outpainting 节点
  双击空白处，搜索并添加 Pad Image for Outpainting 节点。你会看到里面有几个配置，left、top、right、bottom 代表你要往左、上、右、下拓展多少像素。最后一个 feathering 是调整边缘平滑度的，如果你想要过度更自然可以将它调大一点，但它会导致画面有种涂抹感。
  
  ### 连接节点
  第二步，Load Image 节点要和 Pad Image for Outpainting 左端点相连，Pad Image for Outpainting 右边则和 VAE Encode（for Inpainting）左端点相连。

  ### 调整参数
  在 CLIP Text Encode（Prompt）里你可以补充输入额外的信息，另外按照我的经验，VAE Encode（for Inpainting）里的 grow_mask_by 参数要稍微调大点，我一般会调到大于 10：
  <br/>
  <PhotoProvider>
    <PhotoView src="/comfyui-inoutpainting/005.png">
        <img src="/comfyui-inoutpainting/005.png" alt="" />
    </PhotoView>
  </PhotoProvider>
</Steps>

<Subscribe />