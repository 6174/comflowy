import { Steps, Callout, Tabs } from 'nextra-theme-docs';
import { PhotoProvider, PhotoView } from 'react-image-previewer';
import Subscribe from "components/subscribtion";

# ControlNet Advanced

<Callout type="warning" emoji="⚠️">
  Before starting this chapter, please download the following models and place the model files in the corresponding folders:
  * [Dreamshaper](https://civitai.com/models/4384/dreamshaper): Place it within the models/checkpoints folder in ComfyUI.
  * [ControlNet Scribble](https://huggingface.co/lllyasviel/sd-controlnet-scribble/resolve/main/diffusion_pytorch_model.safetensors?download=true): Place it within the models/controlnet folder in ComfyUI.
  * [ControlNet Openpose](https://huggingface.co/lllyasviel/sd-controlnet-openpose/resolve/main/diffusion_pytorch_model.safetensors?download=true): Place it between the models/controlnet folder in ComfyUI.
  * [ControlNet Canny](https://huggingface.co/lllyasviel/ControlNet-v1-1/resolve/main/control_v11p_sd15_canny.pth): Place it between the models/controlnet folder in ComfyUI.
</Callout>

## Image pose ControlNet workflow

But if you can't directly draw the pose, you can try importing a picture you think is appropriate, and then convert it into a pose through the plugin, and then input it into the ControlNet model. This way you can control the pose of the character generated by the model through the image.

The method is also simple.
<Steps>
  ### Download Plugin
  First, you need to download a plugin called [ComfyUI's ControlNet Auxiliary Preprocessors](https://github.com/Fannovel16/comfyui_controlnet_aux?tab=readme-ov-file). There are two ways to install:

  <Tabs items={['ComfyUI-Manager (Recommended)', 'Github']}>
    <Tabs.Tab>
      If you have installed ComfyUI-Manager, you can directly search and install this plugin in ComfyUI-Manager.

      The method to install ComfyUI-Manager, and plug-ins can refer to the tutorial [Install Plugins](../../preparation-for-study/optional/custom-nodes).
    </Tabs.Tab>
    <Tabs.Tab>
      If you don't want to install ComfyUI-Manager, you can directly download this plugin on Github, and then put it in the `custom_nodes` folder in ComfyUI. Then restart ComfyUI.
      <Callout type="warning" emoji="⚠️">
        Please note that after restarting ComfyUI, you can double-click on a blank place, and then enter the node names in the plugin. If you can search for it, it means the plugin is installed successfully. If not, try refreshing the browser page, or close the browser page and reopen it, and then search to see if you can find it.
      </Callout>
    </Tabs.Tab>
  </Tabs>
  ### Insert DWPose Estimation Node
  Double-click on a blank place, enter DWPose Estimation in the search box, and then add this node. Then connect this node's left endpoint with the Load Image node. Parameter configuration is as follows:
  * detect_hand: disable
  * detect_body: enable
  * detect_face: disable
  * resolution: 512 (because the image we generate is 512 * 512 so here is set to 512 * 512)
  * bbox_detector: yolox_l.onnx
  * pose_estimator: dw-ll_ucoco_384.onnx

  The first three, because we mainly want to control the pose of the character, so here we only need to detect the body of the character. The last two settings can be faster.
  ### Add Upscale Image Node
  The addition of this step is mainly to make the resolution of the picture consistent with the resolution of the generated picture, so as to better control the picture generated by the model. We can also add an Upscale Image node, and then connect the right endpoint of DWPose Estimation with the left endpoint of Upscale Image. The parameter configuration is as follows:
  * upscale_method: nearest-exact
  * width: 512
  * height: 512
  * crop: disable
  
  Because the arrangement of the pixels in the pose image is quite regular, we choose nearest-exact, and then set the width and height to match the generated image, and finally disable crop.

  After adding this node, we can connect the right endpoint of Upscale Image with the left endpoint of Apply ControlNet.

  Also, if you want to get the pose image, you can add a Preview Image node, and then connect it with the right endpoint of DWPose Estimation, so you can see the pose image.
  <br/>
  <PhotoProvider>
    <PhotoView src="/comfyui-controlnet/008.png">
        <img src="/comfyui-controlnet/008.png" alt="" />
    </PhotoView>
  </PhotoProvider>

</Steps>

## Image canny ControlNet workflow
The fourth use of ControlNet is to control the images generated by the model through Canny edge maps. The advantage of this method is that you can control the edges of the images generated by the model with Canny edge maps, like this:
<PhotoProvider>
  <PhotoView src="/comfyui-controlnet/011.png">
      <img src="/comfyui-controlnet/011.png" alt="" />
  </PhotoView>
</PhotoProvider>

As you can see from the example above, Canny is somewhat similar to the first Scribble. Canny generates edge maps from existing images, while Scribble involves sketching. Its workflow is also quite simple and you can refer to the Pose ControlNet workflow. All you need to do is replace the DWPose Estimation node with the Canny node.
<br/>
<PhotoProvider>
  <PhotoView src="/comfyui-controlnet/012.png">
      <img src="/comfyui-controlnet/012.png" alt="" />
  </PhotoView>
</PhotoProvider>

<Subscribe />