import { Steps, Callout, Tabs } from 'nextra-theme-docs';
import { PhotoProvider, PhotoView } from 'react-image-previewer';

# SD Prompt 基础

了解完 ComfyUI 的所有基础节点和操作后，你应该就能使用 ComfyUI 生成图片了。

但是，生成的图片效果可能并不是你想要的，比如你想要生成的图片是动漫风格的，但生成的图片却是真人风格的，这时你就需要通过某些手段让 AI 生成特定风格的图片。要想调整图片风格，有多种方法：

* **方法一**：通过 prompt 来影响生成图片的效果。这个是最简单的做法。基本上使用 default workflow 就能实现。本章会介绍如何使用 prompt 来调整图片风格。同时介绍一些更高效的方法。
* **方法二**：通过加载不同的 Checkpoint 模型来影响生成图片的效果。这个是最简单的做法，你可以查看基础选修里的 [模型推荐](./basic-optional/model-recommendation) 了解行业常用模型。
* **方法三**：通过 LoRA 来影响生成图片的效果。这个方法稍微复杂一些，但是相较于方法一，可用的模型会更多，而且文件也小非常多。下一章我会给大家介绍一下 LoRA 的使用方法。

<Callout type="warning" emoji="⚠️">
  考虑到 SDXL 生图效果更好，所以本章节主要介绍 SDXL 的 Prompt。所以正式开始学习本章前，请先下载以下模型，并将模型文件放到对应的文件夹内：
  * [SDXL 1.0 Base](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main)：将其放到 ComfyUI 里的 models/checkpoints 文件夹内。
  * [SDXL 1.0 Refiner](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/tree/main)：将其放到 ComfyUI 里的 models/checkpoints 文件夹内。
</Callout>

## 基本原则

介绍如何写 prompt 前，我们先来介绍下写 prompt 的基本原则。

### 原则一：prompt 不是越长越好
很多人刚学习 prompt 时，会觉得 prompt 越长越好，但实际上这是不对的。精准表达你的意图才是最重要的，而不是堆积非常多无用的词语。

另外，长度最好保持在 75 个 token（或约 60 个字）以内。

### 原则二：越重要的词放在靠前的位置
很多人在写 prompt 时，会较常忽略这一点。比如说，如果你想要生成一张猫的图片，那么你应该将「猫」这个词放在靠前的位置，而不是放在靠后的位置。

### 原则三：善用符号

* 使用逗号分隔：虽然 SDXL 在语意理解上已经有了很大的提升，但是在使用 prompt 时，还是建议使用逗号来分隔不同的意图。
* 使用 () 调整权重：你可以输入 `(keyword:weight)` 方式来控制关键词的权重，比如 `(hight building: 1.2 )` 就意味着 hight building 的权重变高，如果填写的权重数小于 1，则意味着这个词的权重会变低，生成的图与这个词更不相关。

## 基本模板

了解完基本原则后，我们介绍下写 prompt 的模板，一般 prompt 会包含以下内容：
1. **Subject**：因为主体是最重要的，所以主体一般会放在首位。
2. **Environment**：环境包含：
    * 主体周围的环境，比如说「在一片森林里」、「在一片草地上」等等。
    * 灯光，比如「闪电」、「月光」等等。
    * 天气，比如「下雨」、「下雪」等等。
3. **Medium**：媒介可以是图片的拍摄媒介，如「相机」，亦或者承载的媒介，比如「油画」。
4. **Style**：可以用 4W 记忆：
    * When：什么年代的风格？
    * Who：你想要谁的风格？（人或组织）
    * What：什么艺术类型的风格？或者艺术运动的风格？
    * Where：什么国家的风格？

<Callout emoji="💡">
  如果你还学习过我的 [Midjourney 的教程](https://learningprompt.wiki/docs/midjourney/mj-tutorial-text-prompt/framework-summary)，你会发现 SD 的 prompt 少了「构图」这一部分。这是因为，我认为构图最好使用其他方式输入给模型，比如 ControlNet 或 img2img 等方式通过图片传给模型（这些在中级篇会介绍），而不是直接写在 prompt 里。这样模型的输出会更符合预期一些。
</Callout>

## 学习 prompt 的方法

其实了解完 prompt 的基本原则和模板后，你就已经可以写 prompt 并生成图片了。但是，我认为绝大数人（包括我）其实很难一次就生成你脑海中满意的图片。原因是：

* 绝大多数人缺乏对美的认知：这是一个很大的问题，因为你不知道你想要的图片是什么样的，所以你也不知道该怎么写 prompt。
* 绝大多数人缺乏美术相关知识：即使你知道什么是美，但是你不知道该怎么表达出来，比如如果你根本不知道世界上有一名画家叫「梵高」，那你不可能会在 prompt 里写出「梵高风格」这样的词语。

那有没有解决方案呢？

**我觉得最佳的方法是「先模仿后超越」。** 先去看别人怎么写，然后根据自己的需求进行修改，并且通过控制变量的方式去多尝试，比如一次只改一个词，这样你就能知道每个词对生成图片的影响。

我推荐几个不错的学习网站：

* [Civitai](https://civitai.com/images)：大名鼎鼎的 C 站，这个应该是目前全球最大的 AI 图片社区，我在那学到了非常多东西。
* [PromptHero](https://prompthero.com/)：这也是一个很不错的 AI 图片社区，但感觉比 Civitai 小一些。
* [Learning Prompt](https://learningprompt.wiki/)：虽然我当年写的教程是针对 Midjourney 的，但里面场景案例对于学习 Stable Diffusion 依然有参考意义。

## SDXL prompt styler workflow
你可能有用过一些基于 Stable Diffusion 的产品，他们比 Midjourney 会多一个 Style 的选项，这个选项就是用来调整图片风格的。有了这个功能，你就不需要在 prompt 里写 Style 了。

那在 ComfyUI 里，是否也能实现呢？答案是肯定的。

我们可以使用一个叫 SDXL prompt styler 的插件来实现这个功能。以下是操作步骤。

<Steps>
  ### 下载 & 安装 SDXL prompt styler 插件
  首先，需要下载并安装插件。我们会用到 ComfyUI Manager 协助我们完成这个操作。如果你没有安装 ComfyUI Manager，可以查看 [安装插件](../preparation-for-study/custom-nodes) 一文。
  点击右侧面板的 Manager 按钮，然后在弹出的窗口里，点击「Install custom nodes」按钮，然后在弹出的窗口里，搜索「SDXL prompt styler」，然后点击「Install」按钮进行安装。
  <Callout type="info">
    注意，安装完成后，需要点击一下 restart 按钮，重启 ComfyUI。
    如果你在下一步操作时，发现没有「SDXL prompt styler」这个节点，但你已经重启过 ComfyUI，那么请刷新一下页面。
  </Callout>
  
  ### 加载 Default workflow
  点击右侧面板的 Load Default 按钮，加载默认的 workflow。

  ### 添加 SDXL prompt styler 节点
  接着点击右键 -> Add Node -> utils -> SDXL prompt styler，添加这个节点。
  添加后，你会发现这个节点可以填写 postive 和 negative text 这两个其实是填写 prompt 的输入框。然后下方还有一个 style 的选项，点击后可以看到各种风格，感觉自己的需要选择即可。

  ### 连接节点
  这个节点连起来稍稍有点复杂。
  1. 你需要右键点击与 KSampler positive 端点相连的 CLIP Text Encode(Prompt) 节点。
  2. 然后在菜单里点击 Convert text to input，此时 CLIP Text Encode(Prompt) 节点的输入框会消失，同时左端点多了一个 text 端点。
  3. 此时需要将此端点与 SDXL prompt styler 节点的 positive text 端点连接起来。
  4. 另一个 CLIP Text Encode(Prompt) 节点的重复上述操作。
  
  连接后的 Workflow 是这样的：
  <br/>
  <PhotoProvider>
    <PhotoView src="/stable-diffusion-prompt/002.png">
      <img src="/stable-diffusion-prompt/002.png" alt="" />
    </PhotoView>
  </PhotoProvider>
</Steps>

## Batch image workflow
除了选择 Style 外，还有一个能提高出图效率的是一次生成多张图片。在前面介绍 ComfyUI 的基础节点的时候，我提到可以通过调整某个节点的参数，就可以一次生成多张图片。

不妨回忆下如何出多张图呢？

<Tabs items={['提示', '答案']}>
  <Tabs.Tab>
    如果忘记了，可以回去看看 [ComfyUI 基础①](./comfyui-foundation) 一文。
  </Tabs.Tab>
  <Tabs.Tab>
    答案就是在 Empty Latent Image 的 batch_size。如果你将此参数设置成 4，就意味着每次生成 4 张图。

    但你可能会想，想要放大其中一张图应该怎么办呢？方法很简单：
    <Steps>
      ### 新增 Latent from Batch 节点
      首先右键 → Add Node → latent → batch → Latent from Batch，添加这个节点。
      
      ### 新增 VAE 和 Save Image 节点
      然后，还需要新增两个节点，VAE Decode 和 Save Image。你可以在右键 → Add Node → latent 里找到 Decode，然后再右键 → Add Node → image 里找到 Save Image 节点。

      ### 连接节点
      接着，我们需要将 Latent from Batch 节点的左端点与 KSampler 的右端点相连，其右端点跟新增的 VAE Decode 节点的左端点相连，然后再将 VAE Decode 节点的右端点与 Save Image 节点的左端点相连。VAE Decode 还有一个没连接的 vae 就跟 checkpoints 里的 vae 相连即可。

      ### 调整参数
      在 Latent from Batch 节点，你会看到这个节点有两个参数设置项：
      * batch_index：输入你要放大的第几张图，但需要注意，这里的索引是从 0 开始的，也就是说，如果你想要放大第一张图，那么这里需要填 0。
      * length：指想要提取图片的数量，如果输入 1，就是提取一张。
      
      最后，我们要将 KSampler 的 control_after_generate 设置成 fixed，这样设置好后，然后点击 Queue Prompt 生成图片。生成完图片后，你可以调整 Latent from Batch 节点的 batch_index 参数，然后再点一下 Queue Prompt，就能看到不同的图片了。

      如果你要生成新的 4 张图，就将 control_after_generate 设置成 increment，然后再点一下 Queue Prompt 即可。
      
      记得当你要切换 batch_index 之前，要：
      * 将 seed 数剪 1。
      * 重新将 control_after_generate 设置为 fixed。

      <br/>
      <PhotoProvider>
        <PhotoView src="/stable-diffusion-prompt/003.png">
          <img src="/stable-diffusion-prompt/003.png" alt="" />
        </PhotoView>
      </PhotoProvider>

      <Callout emoji="💡">
        还有一个小技巧，你可以通过鼠标左键点击节点后，CTRL + M 来启用/禁用节点。在上面的示例中，你可以禁用 Latent From Batch 节点以及连接的 VAE Decode 和 Save Image，只有在遇到你感兴趣的图像时才重新启用它们。
      </Callout>
    </Steps>
  </Tabs.Tab>
</Tabs>