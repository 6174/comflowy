import { Steps, Callout, Tabs } from 'nextra-theme-docs';
import { PhotoProvider, PhotoView } from 'react-image-previewer';
import Subscribe from "components/subscribtion";

# SD Prompt 基础

了解完 ComfyUI 的所有基础节点和操作后，你应该就能使用 ComfyUI 生成图片了。

但是，生成的图片效果可能并不是你想要的，比如你想要生成的图片是动漫风格的，但生成的图片却是真人风格的，这时你就需要通过某些手段让 AI 生成特定风格的图片。要想调整图片风格，有多种方法：

* **方法一**：通过 prompt 来影响生成图片的效果。这个是最简单的做法。基本上使用 default workflow 就能实现。本章会介绍如何使用 prompt 来调整图片风格。同时介绍一些更高效的方法。
* **方法二**：通过加载不同的 Checkpoint 模型来影响生成图片的效果。这个是最简单的做法，你可以查看基础选修里的 [模型推荐](./basic-optional/model-recommendation) 了解行业常用模型。
* **方法三**：通过 LoRA 来影响生成图片的效果。这个方法稍微复杂一些，但是相较于方法一，可用的模型会更多，而且文件也小非常多。后续我会给大家介绍一下 LoRA 的使用方法。

<Callout type="warning" emoji="⚠️">
  考虑到 SDXL 生图效果更好，所以本章节主要介绍 SDXL 的 Prompt。所以正式开始学习本章前，请先下载以下模型，并将模型文件放到对应的文件夹内：
  * [SDXL 1.0 Base](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main)：将其放到 ComfyUI 里的 models/checkpoints 文件夹内。
  * [SDXL 1.0 Refiner](https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/tree/main)：将其放到 ComfyUI 里的 models/checkpoints 文件夹内。
</Callout>

## 基本原则

介绍如何写 prompt 前，我们先来介绍下写 prompt 的基本原则。

### 原则一：prompt 不是越长越好
很多人刚学习 prompt 时，会觉得 prompt 越长越好，但实际上这是不对的。精准表达你的意图才是最重要的，而不是堆积非常多无用的词语。

另外，长度最好保持在 75 个 token（或约 60 个字）以内。

### 原则二：越重要的词放在靠前的位置
很多人在写 prompt 时，会较常忽略这一点。比如说，如果你想要生成一张猫的图片，那么你应该将「猫」这个词放在靠前的位置，而不是放在靠后的位置。

### 原则三：善用符号

* 使用逗号分隔：虽然 SDXL 在语意理解上已经有了很大的提升，但是在使用 prompt 时，还是建议使用逗号来分隔不同的意图。
* 使用 () 调整权重：你可以输入 `(keyword:weight)` 方式来控制关键词的权重，比如 `(hight building: 1.2 )` 就意味着 hight building 的权重变高，如果填写的权重数小于 1，则意味着这个词的权重会变低，生成的图与这个词更不相关。

## 基本模板

了解完基本原则后，我们介绍下写 prompt 的模板，一般 prompt 会包含以下内容：
1. **Subject**：因为主体是最重要的，所以主体一般会放在首位。
2. **Environment**：环境包含：
    * 主体周围的环境，比如说「在一片森林里」、「在一片草地上」等等。
    * 灯光，比如「闪电」、「月光」等等。
    * 天气，比如「下雨」、「下雪」等等。
3. **Medium**：媒介可以是图片的拍摄媒介，如「相机」，亦或者承载的媒介，比如「油画」。
4. **Style**：可以用 4W 记忆：
    * When：什么年代的风格？
    * Who：你想要谁的风格？（人或组织）
    * What：什么艺术类型的风格？或者艺术运动的风格？
    * Where：什么国家的风格？

<Callout emoji="💡">
  如果你还学习过我的 [Midjourney 的教程](https://learningprompt.wiki/docs/midjourney/mj-tutorial-text-prompt/framework-summary)，你会发现 SD 的 prompt 少了「构图」这一部分。这是因为，我认为构图最好使用其他方式输入给模型，比如 ControlNet 或 img2img 等方式通过图片传给模型（这些在中级篇会介绍），而不是直接写在 prompt 里。这样模型的输出会更符合预期一些。
</Callout>

## 学习 prompt 的方法

其实了解完 prompt 的基本原则和模板后，你就已经可以写 prompt 并生成图片了。但是，我认为绝大数人（包括我）其实很难一次就生成你脑海中满意的图片。原因是：

* 绝大多数人缺乏对美的认知：这是一个很大的问题，因为你不知道你想要的图片是什么样的，所以你也不知道该怎么写 prompt。
* 绝大多数人缺乏美术相关知识：即使你知道什么是美，但是你不知道该怎么表达出来，比如如果你根本不知道世界上有一名画家叫「梵高」，那你不可能会在 prompt 里写出「梵高风格」这样的词语。

那有没有解决方案呢？

**我觉得最佳的方法是「先模仿后超越」。** 先去看别人怎么写，然后根据自己的需求进行修改，并且通过控制变量的方式去多尝试，比如一次只改一个词，这样你就能知道每个词对生成图片的影响。

我推荐几个不错的学习网站：

* [Civitai](https://civitai.com/images)：大名鼎鼎的 C 站，这个应该是目前全球最大的 AI 图片社区，我在那学到了非常多东西。
* [PromptHero](https://prompthero.com/)：这也是一个很不错的 AI 图片社区，但感觉比 Civitai 小一些。
* [Learning Prompt](https://learningprompt.wiki/)：虽然我当年写的教程是针对 Midjourney 的，但里面场景案例对于学习 Stable Diffusion 依然有参考意义。

## Batch image workflow
为了提高出图效率，我会建议你这么做：
* 选择相对较快的模型出图，如果你是用的 SDXL，那么就选择 SDXL Base。或者使用最新的 Turbo。
* ComfyUI 生成图片跟 Midjourney 有个很大的区别，就是它不像 Midjourney 那样并发生图，而是一张一长图出。所以在实验 Prompt 的时候，建议先一次出一张图。不满意，就多点击几次 Queue Prompt。
* 当你满意了，就可以使用一次生成多张图片了。

在前面介绍 ComfyUI 的基础节点的时候，我提到可以通过调整某个节点的参数，就可以一次生成多张图片。

不妨回忆下如何出多张图呢？

<Tabs items={['提示', '答案']}>
  <Tabs.Tab>
    如果忘记了，可以回去看看 [ComfyUI 基础①](./comfyui-foundation) 一文。
  </Tabs.Tab>
  <Tabs.Tab>
    **答案就是在 Empty Latent Image 的 batch_size。如果你将此参数设置成 4，就意味着每次生成 4 张图。**

    但你可能会想，生成的四张图在 ComfyUI 里有点小，如果我想单独看其中一张图应该怎么办呢？方法很简单：

    <br/>
      <PhotoProvider>
        <PhotoView src="/stable-diffusion-prompt/003.png">
          <img src="/stable-diffusion-prompt/003.png" alt="" />
        </PhotoView>
      </PhotoProvider>
    <Steps>
      ### 新增 Latent from Batch 节点
      首先右键 → Add Node → latent → batch → Latent from Batch，添加这个节点。
      
      ### 新增 VAE 和 Save Image 节点
      然后，还需要新增两个节点，VAE Decode 和 Save Image。你可以在右键 → Add Node → latent 里找到 Decode，然后再右键 → Add Node → image 里找到 Save Image 节点。

      ### 连接节点
      接着，我们需要将 Latent from Batch 节点的左端点与 KSampler 的右端点相连，其右端点跟新增的 VAE Decode 节点的左端点相连，然后再将 VAE Decode 节点的右端点与 Save Image 节点的左端点相连。VAE Decode 还有一个没连接的 vae 就跟 checkpoints 里的 vae 相连即可。

      ### 调整参数
      在 Latent from Batch 节点，你会看到这个节点有两个参数设置项：
      * batch_index：输入你要放大的第几张图，但需要注意，这里的索引是从 0 开始的，也就是说，如果你想要放大第一张图，那么这里需要填 0。
      * length：指想要提取图片的数量，如果输入 1，就是提取一张。
      
      最后，我们要将 KSampler 的 control_after_generate 设置成 fixed，这样设置好后，然后点击 Queue Prompt 生成图片。生成完图片后，你可以调整 Latent from Batch 节点的 batch_index 参数，然后再点一下 Queue Prompt，就能看到不同的图片了。

      如果你要生成新的 4 张图，就将 control_after_generate 设置成 increment，然后再点一下 Queue Prompt 即可。
      
      记得当你要切换 batch_index 之前，要：
      * 将 seed 数减 1。
      * 重新将 control_after_generate 设置为 fixed。

      <Callout emoji="💡">
        还有一个小技巧，你可以通过鼠标左键点击节点后，CTRL + M 来启用/禁用节点。在上面的示例中，你可以禁用 Latent From Batch 节点以及连接的 VAE Decode 和 Save Image，只有在遇到你感兴趣的图像时才重新启用它们。
      </Callout>
    </Steps>
  </Tabs.Tab>
</Tabs>

<Subscribe />