---
date:  February 1th, 2024
image: /blog/AI-weekly-005/banner.png
---

# AI Weekly #005

import { PhotoProvider, PhotoView } from 'react-image-previewer';
import Subscribe from "components/subscribtion";

## 🆕 更新了什么？

<br/>
<PhotoProvider>
  <PhotoView src="/space/001.png">
    <img src="/space/001.png" alt="" />
  </PhotoView>
</PhotoProvider>

**产品更新：**

- 我们支持 Windows 版本了！！不过因为这是 Win 的第一个版本，你可能会遇到一些问题，望见谅，如果遇到问题，欢迎在 Discord 里留言。
- 现在你还可以在产品里看教程。
- 与此同时我们还修复了不少 bug，提升了安装成功率。

下载链接：https://github.com/6174/comflowyspace/releases

**上周新增教程：**

- [如何将 ComfyUI 应用于室内设计 ②](https://www.comflowy.com/zh-CN/blog/krita-and-comfyui)：上期我们介绍了如何在室内设计场景使用 ComfyUI，本期我们介绍下如何使用 Krita 和 ComfyUI 一起使用。

## 🤩 每周 AI 精选

### 📄 值得关注的论文 & 技术

* [**Lumiere 视频生成技术：**](https://arxiv.org/abs/2401.12945)

这是一个由 Google Research 开发的文本到视频的扩散模型，采用了创新的空间时间 U-Net 架构，支持多种视频生成和编辑功能（文本到视频、图像到视频、风格化视频生成、视频编辑）。能够一次性生成整个视频，且能确保视频的连贯性和逼真度。

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-005/001.png">
    <img src="/blog/AI-weekly-005/001.png" alt="" />
  </PhotoView>
</PhotoProvider>

* [**26 种多模态大模型研究报告：**](https://arxiv.org/abs/2401.13601)

这篇论文对目前市面上 26 种多模态大语言模型（MM-LLMs）进行了全面的研究和分析。提供了对多模态大语言模型的深入了解信息，详细介绍了模型架构和训练流程的设计。26 种现存的 MM-LLMs，每种模型都有其独特的设计和功能，这篇论文讨论了其未来研究方向的同时，也提供了实时跟踪这些模型最新发展的资源，值得一看。

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-005/002.png">
    <img src="/blog/AI-weekly-005/002.png" alt="" />
  </PhotoView>
</PhotoProvider>

* [**SUPIR:**](https://arxiv.org/abs/2401.13627)

SUPIR 通过增加模型的规模（即增加模型的参数数量）提升图像修复的能力，不仅能够修复图像中的错误或损坏，还能根据文本提示进行智能修复。例如根据描述来改变图像中的特定细节。这样的处理方式提升了图像修复的质量和智能度，使得模型能够更准确、更灵活地恢复和改进图像。

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-005/003.png">
    <img src="/blog/AI-weekly-005/003.png" alt="" />
  </PhotoView>
</PhotoProvider>

* [**Diffuse to Choose:**](https://arxiv.org/abs/2401.13795)

这是一个在线购物“虚拟试穿”模型，这个模型能让你将任何商品放入任何环境中，并和环境完美融合。比如，你可以把一个在线商店的椅子放进你的客厅的照片里，看看它实际放在那里会是什么样子。简而言之，它帮助用户更好地了解产品在真实环境中的样子，提高了在线购物的体验。

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-005/004.png">
    <img src="/blog/AI-weekly-005/004.png" alt="" />
  </PhotoView>
</PhotoProvider>

### 🛠️ 值得尝试的产品

* [**Nijijourney V6:**](https://nijijourney.com/en/)

Niji V6 现在能够进一步理解各种主题，并生成该主题作品。即使是一些平时动漫里不常见的主题也能生成。如果你想要的不只是动漫风格，Niji V6 还有一个“RAW 模式”，可以生成看起来更真实的图片。如果 Niji V6 不理解某个概念，用户也可以通过解释来帮助它理解。

他们计划在 2 月底的全面发布中引入一系列新功能，如 vary(Region 调整图片的某个部分)、pan（移动）和 zoom（缩放），进一步增强用户体验和创作灵活性。

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-005/005.png">
    <img src="/blog/AI-weekly-005/005.png" alt="" />
  </PhotoView>
</PhotoProvider>

* [**ElevenLabs AI 配音/视频翻译工具：**](https://elevenlabs.io/dubbing)

这是一个全自动 AI 工具，你只需要上传视频或者粘贴视频链接，就能在几十秒到几分钟内将你的视频翻译成 29 种语言。更厉害的是，它还可以克隆原视频里面的声音，来帮你配音，就算是视频里面有多个人说话也能全部克隆翻译。除了视频文件，它还能处理音频文件，如 MP3、MP4 等。

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-005/006.png">
    <img src="/blog/AI-weekly-005/006.png" alt="" />
  </PhotoView>
</PhotoProvider>

* [**StreamRAG：**](https://github.com/video-db/StreamRAG)

StreamRAG 是一个视频搜索和流媒体代理工具，它可以让你在 2 分钟内基于你的视频数据构建一个定制的个人 GPT，然后你可以和你的视频进行对话。也能够迅速浏览存储的大量视频资料，帮你找到想要搜索的内容或主题的视频片段，并把这些片段展示给你，这样你就能直接观看到与你搜索内容相关的视频部分。

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-005/007.png">
    <img src="/blog/AI-weekly-005/007.png" alt="" />
  </PhotoView>
</PhotoProvider>

* [**轻子搜索：**](https://search.lepton.run/)

轻子搜索（Lepton Search）是贾扬清团队，仅用 500 行代码打造的一个 AI 搜索引擎。我平时在查资料时，经常使用困惑（Perplexity）引擎，但这个轻子 AI 搜索，已经能达到与困惑引擎相似的效果了。他仅用 500 行代码，就打造“轻子搜索”，作为 Demo 演示，而不是正式产品，只为向开发者展示“天下没有难构建的 AI 应用”。

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-005/008.png">
    <img src="/blog/AI-weekly-005/008.png" alt="" />
  </PhotoView>
</PhotoProvider>


<Subscribe />





