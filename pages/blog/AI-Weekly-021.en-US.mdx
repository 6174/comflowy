---
date: May 25th, 2024
image: /blog/AI-weekly-021/banner.png
title: AI Weekly 021
---

import { PhotoProvider, PhotoView } from 'react-image-previewer';
import Subscribe from "components/subscribtion";

# AI Weekly 021

## üÜï What's New?

New blog : [How to Generate Clay Textures with ComfyUI?](https://www.comflowy.com/blog/Clay-Textures)

Download link : [Comflowyspace](https://github.com/6174/comflowyspace/releases)

## Weekly‚Äòs AI highlights

### ü™êWorkflow worth trying

[**her**](https://openart.ai/workflows/datou/her/A45EfKxrlB8MkFItvsym)

The inspiration for this workflow comes from the movie poster for "Her" ÔºåThrough this workflow, you can effortlessly incorporate your thoughts and emotions into the movie poster, creating a unique piece that reflects both your personal style and the film's theme.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/001.png">
    <img src="/blog/AI-weekly-021/001.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

[**SKETCH TO REALFACE**](https://openart.ai/workflows/xiongmu/sketch-to-realface/TKilAKd2dMgTUseMTTsI)

This workflow only requires you to upload a simple sketch, whether it's a hand-drawn doodle or a digital drawing. It can then generate a photo with a lifelike quality, maintaining a high degree of detail and resemblance to the original sketch. Additionally, it will finely adjust the skin tone and lighting effects of the person in the image to enhance the photo's realism.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/002.png">
    <img src="/blog/AI-weekly-021/002.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

You can subscribe to our [**newsletter**](https://comflowy.substack.com/), or join our [**Discord**](https://discord.gg/cj623WvcVx) to get the latest tutorials.

### üèóÔ∏èPlugins worth trying

[**ComfyUI-Anyline**](https://github.com/TheMistoAI/ComfyUI-Anyline)

Anyline is a ControlNet preprocessing model that can accurately extract object edges, image details, and text content from most images. Users can input any type of image and quickly obtain a line drawing with clear edges, well-preserved details, and high text fidelity. This line drawing can then be used as an input for generating stable diffusion conditions.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/003.png">
    <img src="/blog/AI-weekly-021/003.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

[**ComfyUI-Frame-Interpolation**](https://github.com/Fannovel16/ComfyUI-Frame-Interpolation)

This is a video frame interpolation toolkit designed to generate intermediate frames between video frames, thereby enhancing the smoothness and quality of the video. It offers various efficient frame interpolation algorithm implementations, supporting memory optimization and scheduling multiplier configuration to meet different video processing needs. The strength of this toolkit lies in its flexibility and ease of use, allowing users to quickly achieve frame interpolation effects through customizable nodes. Additionally, it supports non-CUDA devices, broadening its applicability.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/004.png">
    <img src="/blog/AI-weekly-021/004.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

### üìÑ Noteworthy papers and technic

[**Chameleon**](https://arxiv.org/abs/2405.09818)

Chameleon is a hybrid modality model developed by Meta's FAIR team, based on early fusion tokens. It can understand and generate arbitrary sequences of images and text, including visual question answering, image captioning, text generation, image generation, and long-form mixed modality generation. Chameleon can seamlessly switch between different data types during processing. For example, it can generate a related image after producing a segment of text, or generate relevant text while describing an image.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/005.png">
    <img src="/blog/AI-weekly-021/005.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

[**Slicedit**](https://matankleiner.github.io/slicedit/resources/paper.pdf)

Slicedit is a text-based video editing tool that allows users to precisely edit video content through simple text input. It employs advanced T2I diffusion models to not only retain the original video's structure and smooth motion but also enhance the video's coherence according to the target text. In contrast, Stable Video Diffusion focuses on creating entirely new video content, suitable for content creation, entertainment, and research. Unlike Stable Video Diffusion, Slicedit is dedicated to providing professional video editing services, utilizing precise "slicing" techniques to meet users' needs for editing and modifying existing video content.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/006.png">
    <img src="/blog/AI-weekly-021/006.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

[**Semantic Gaussians**](https://arxiv.org/abs/2403.15624)

Semantic Gaussians is a 3D scene understanding technology that can convert multi-view images into semantic Gaussian points in 3D space. This technology enables dynamic object tracking, multi-part segmentation of complex objects, and intuitive image editing through natural language instructions. For example, it can recognize and segment different parts of a guitar or edit a scene based on user instructions such as "remove the glass bottle."

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/007.png">
    <img src="/blog/AI-weekly-021/007.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

[**TextureDreamer**](https://arxiv.org/abs/2401.09416)

TextureDreamer is an AI model developed by Moonshot AI, specifically designed for generating and processing textures. It can transfer textures onto any 3D model using only 3 to 5 input images. The realistic textures it generates can be used in 3D rendering, game development, film production, and other fields that require high-quality textures.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/008.png">
    <img src="/blog/AI-weekly-021/008.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

[**TRANSAGENTS**](https://arxiv.org/pdf/2405.11804)

TRANSAGENTS is a multi-agent translation system based on large language models (LLMs), specifically designed for the translation of literary texts. By simulating traditional translation workflows, it employs multiple agents with different roles, such as senior editors and translators, to collaborate intelligently. These agents work together to overcome the complexities of literary text translation, thereby improving the quality of the translations.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/009.png">
    <img src="/blog/AI-weekly-021/009.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

### üõ†Ô∏è Products you should try 

[**PictoGraphic**](https://pictographic.io/?ref=producthunt)

PictoGraphic is an illustration library offering over 40,000 images and SVG files, covering a wide range of styles and concepts to meet designers' diverse needs. Here, you can find the illustrations you want for free, or generate custom illustrations in seconds using text prompts.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/010.png">
    <img src="/blog/AI-weekly-021/010.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

[**Apriora**](https://www.apriora.ai/)

Apriora is an intelligent recruitment assistant that significantly enhances hiring efficiency through automated interview scheduling and real-time video interview capabilities. Apriora conducts interactive real-time video interviews, covering various formats such as technical screening, phone screening, and coding assessments. After the interview, the system provides customized reports to help recruitment teams make informed hiring decisions based on the company's needs.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/011.png">
    <img src="/blog/AI-weekly-021/011.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

[**Audio Native**](https://elevenlabs.io/blog/audio-native/)

Audio Native is an integrated web-based audio playback tool with automatic speech synthesis capabilities. By partnering with ElevenLabs' text-to-speech technology, it can convert text content on a webpage into audio output. Users only need to insert a small piece of HTML code into the webpage to embed the Audio Native player, enabling voice playback of the content.

<br/>
<PhotoProvider>
  <PhotoView src="/blog/AI-weekly-021/012.png">
    <img src="/blog/AI-weekly-021/012.png" alt="" className="rounded-lg"/>
  </PhotoView>
</PhotoProvider>

<Subscribe />
































